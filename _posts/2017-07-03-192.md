---
title: 汉字屋论证与人工智能哲学
layout: post
permalink: /192
categories:
  - MOOC
tags:
  - AI
  - 哲学
---

1950 年[图灵](https://zh.wikipedia.org/wiki/%E8%89%BE%E4%BC%A6%C2%B7%E5%9B%BE%E7%81%B5)提出了著名的“[图灵测试](https://zh.wikipedia.org/wiki/%E5%9B%BE%E7%81%B5%E6%B5%8B%E8%AF%95)”，成为“人工智能之父”，以图灵为原型的电影《模仿游戏》也被搬上荧幕。“图灵测试“是人工智能哲学方面第一个严肃的提案，因为”智能“这一概念并没有一个明确的定义。

图灵去世两年后，在 1956 年美国达特矛斯学院的会议上，[麦卡锡](https://zh.wikipedia.org/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E9%BA%A6%E5%8D%A1%E9%94%A1)提出了“人工智能”这一概念。与会的几位元老（麦卡锡、[马文·闵斯基](https://zh.wikipedia.org/wiki/%E9%A9%AC%E6%96%87%C2%B7%E9%97%B5%E6%96%AF%E5%9F%BA)、[司马贺](https://zh.wikipedia.org/wiki/%E5%8F%B8%E9%A9%AC%E8%B4%BA)（赫伯特·西蒙）、[艾伦·纽厄尔](https://zh.wikipedia.org/wiki/%E8%89%BE%E4%BC%A6%C2%B7%E7%BA%BD%E5%8E%84%E5%B0%94)）之后全部获得图灵奖，其中司马贺同时获得了图灵奖和诺贝尔经济学奖，闵斯基对哲学也非常有研究。会议上讨论的内容有自然语言处理、人工神经元网络、计算理论以及机器的创造性等非常前沿的课题。这些人随后在各个高校内建立起研究中心，引领着人工智能几十年的研究方向。

<p align="center">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/49/John_McCarthy_Stanford.jpg/1599px-John_McCarthy_Stanford.jpg" width="100%" ><br/>
“人工智能”命名者 麦卡锡
</p>

美国社会涌现出很多在多个学科都很有造诣的学者，比如[丹尼尔·丹尼特](https://zh.wikipedia.org/wiki/%E4%B8%B9%E5%B0%BC%E7%88%BE%C2%B7%E4%B8%B9%E5%B0%BC%E7%89%B9)，既是哲学家又是认知学家，对计算机也非常有研究。这类学者在交叉学科之间的贡献使得美国社会的研究非常有活力。在我的读书笔记[《硅谷之谜》](https://livc.io/186)中也介绍了跨界人才对美国社会的影响力。然而国内社会对此的宽容和认识还远远不够，比如前几天在听罗永浩和罗振宇的访谈节目，期间罗永浩就提起他在创业初期，很多人质疑“**一个当老师的怎么可能做好手机？**”其实学会欣赏和接受跨界、跨学科人才，并努力成为全才、通才，会对很多研究和思想带来启发。

话题稍扯远了，那么人工智能是怎么和哲学产生关系的？图灵的问题“**机器会思考吗**”的答案是什么？为什么人工智能科学需要哲学的参与？

这就要从“智能”的**定义**说起。

## 人工智能与哲学

### 定义分歧

什么是”智能“？

在“图灵测试”被提出后，对于”智能“有两种比较普遍的认识。

第一种可以理解为“**白盒派**”，他们认为“智能”就是对于所有可能的情况，都有应对的方法。这有点像诸葛亮交给赵云的三个锦囊，告诉他什么时候打开第几个，整体看起来类似一个流程图。

第二种对“智能”的理解为“**黑盒派**”，他们认为人工智能需要模拟人工大脑，因此可以不管人脑在想什么，把输入和输出的映射关系对应好就可以了。

因此，人工智能学科对于“智能”的定义还是有比较大的分歧的，这种分歧几乎和哲学有的一拼，因为哲学里也确实存在着“**哲学应该研究什么**”的重大分歧。这是人工智能可以和哲学交流的一个重要道理。

### 见仁见智

在物理等自然学科中，我们可以通过做实验来验证一个猜想是否正确，一个概念是否存在。比如“[以太理论](https://zh.wikipedia.org/wiki/%E4%BB%A5%E5%A4%AA)”通过实验被科学界抛弃，伽利略比萨斜塔实验验证自由落体等等。在这些学科中，可以通过一个大家都信服的实验证据来证明某一个假设是错的。然而在人工智能学科中，不做实验只做试验，从这一点上看它更像是工科，而不是理科。

<img src="https://upload.wikimedia.org/wikipedia/commons/f/f2/Leaning_Tower_of_Pisa.jpg" width="50%" />

一个人工智能系统是否智能，是否满足人们需求，这是一个仁者见仁智者见智的问题，是一个社会学标准和人类学标准的事情，并没有客观的标准或绝对的答案。这里面的**思辨成分**和哲学很像。举个例子，最近看见有人在群里问“**百度的内容推荐也挺不错的为啥干不过头条？**”，但是他可能不知道百度首页在内网几乎天天被骂……

### 尚未成熟

人工智能这门学科至今也才只有六十岁，它的发展还很不成熟，各路研究彼此竞争，各有优势，这在一定程度上又扩大了哲学在其中的表演舞台。因为如果一个学科非常成熟，大家没有什么内部争论，那么哲学家插话的机会很少。只要他们乱了，哲学家就会浑水摸鱼，乱中取胜。

与“图灵测试”的家喻户晓相比，哲学家[塞尔](https://zh.wikipedia.org/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E7%BD%97%E6%9D%B0%E6%96%AF%C2%B7%E5%B8%8C%E5%B0%94%E5%8B%92)提出的“汉字屋实验”倒是了解的人比较少。他认为**既是计算机通过了图灵测试，也是依然没有智能的**，不管你是真比我强还是看起来比我强，我依然有理由认为你没有我强。这样他自认为一劳永逸地终结了这个话题，然而很多人纷纷跳出来反驳他的论证。

在了解汉字屋实验之间，我们需要先了解一个概念前提，就是强 AI 和弱 AI 的区分。

## 强人工智能与弱人工智能

- 强人工智能：计算机不仅仅是人们用来研究心灵的一种工具，被恰当编程的计算机本身就是一个心灵，具有心智。如果直观上认为计算机只是个工具，那是因为它没有被恰当地编程，只要它被恰当地编程，那么它就具有心智。
- 弱人工智能：计算机只能模拟人类的心智，本身并不是人类心智的组成部分。

**塞尔认为弱 AI 是正确的，强 AI 是错的**。

那么他的论证框架是什么呢？他的**大前提**是：每一种真正的心灵或智能都必须有能力在符号与对象之间建立起一种**语义关系**。比如知道红色是红色，绿色是绿色，水是那种能喝的东西。**小前提**是这种符号和对象之间的语义关系无法通过任何一台被恰当编程的计算机所获取。**结论：计算机本身不可能具有真正的心灵，因此强 AI 无法实现。**

塞尔的汉字屋实验就是用来证明小前提是对的。汉字屋实验是一个“**思想实验**”，是通过使用想象力去进行的实验，所做的都是在现实中无法做到或未做到的实验。著名的思想实验是爱因斯坦的“[双生子佯谬](https://zh.wikipedia.org/wiki/%E5%8F%8C%E7%94%9F%E5%AD%90%E4%BD%AF%E8%B0%AC)”和莱布尼茨的“[磨坊论证](https://en.wikipedia.org/wiki/Leibniz%27s_gap)”。

## 汉字屋实验

汉字屋实验的初始条件是，一个对汉语一窍不通，只说英语的人关在一间只有一个开口的封闭房间中。房间里有一本用英文写成的规则书，指示该如何处理收到的汉语讯息及如何以汉语相应地回复，比如说写着“收到‘你吃了吗’的卡片就把 899 号卡片递回去，899 号卡片上写着‘我吃过了，那你呢’”。房外的人不断向房间内递进用中文写成的问题。房内的人便按照规则书的说明，查找到合适的指示，将相应的中文字符组合成对问题的解答，并将答案递出房间。

最后，汉字屋外面的人分辨不出屋内的人是否真的懂汉语。那么屋内的人算不算真的懂汉语了呢？

![](https://ws1.sinaimg.cn/large/9cd77f2ely1fh72ey7ugvj20cu07r0v7.jpg)

塞尔认为显然屋内的人不懂汉语。尽管房里的人可以以假乱真，让房外的人以为他确确实实说汉语，但是他却压根不懂汉语，因为他不可能通过完成这种输入和输出的传递工作理解任何一个汉语词汇。所以就算将来计算机真的聪明到这个地步了，它也不可能具有智能。

塞尔预设，汉字屋系统和计算机系统有一个很强的**对应关系**。在上述过程中，房外人的角色相当于程序员，房中人相当于计算机，而规则书则相当于计算机程序：每当房外人给出一个输入，房内的人便依照手册给出一个答复（输出）。而正如房中人不可能通过手册理解中文一样，计算机也不可能通过程序来获得理解力。既然计算机没有理解能力，所谓“计算机有智能”便更无从谈起了。计算机即使能够恰当地应答所有的人类语言提出的问题，它也没有办法真正地理解人类的语言。

塞尔的汉字屋实验从某种程度上是**图灵测试的衍生版本**，图灵认为计算机能否通过图灵测试是计算机是否具有智能的关键指标，而塞尔的观点相反，他认为即使通过了关于汉语的汉字屋实验，计算机依然没有智能。

但是这个论证并没有说服大多数的哲学家，那么大家是怎么反驳他的呢？

### 1. 他心应答

[他心应答](https://zh.wikipedia.org/wiki/%E4%BB%96%E5%BF%83%E5%95%8F%E9%A1%8C)：假如我要判断你塞尔这个人懂不懂英语，如果按照汉字屋的论证，我不是你，我怎么知道你是否真的懂英语？你给我的只是那些看似懂英语的表现，有一种可能你根本不懂英语，在你脑中有一个小人接受了这些信息，按照一个手册（规则书）知道应该把哪些英文输出，让我误以为你懂英文。

按照这个思路，**可以用汉字屋论证去怀疑身边任何一个人是否懂任何一种语言**，这和塞尔论证的初衷是不一样的。塞尔论证的初衷是为了显示人和机器不一样，人比机器要高明，但是这个论证实际上把人也给灭掉了，因此论证失败。

正因为我们没有人愿意接受这样一种很疯狂的观点，认为人本身都是不懂任何语言的，所以我们用来捍卫人的标准也可以用来捍卫机器：**既然我们判断人是否懂英语的标准是判断是不是有一个恰当的输入输出关系，那么我们用来判断机器是否懂语言的标准也应该是这样。**

### 2.以偏概全

第二种思路认为，我承认汉字屋中的人是不懂汉语的，但是类比的计算机系统不仅仅只屋内的人，还包括了规则书，和规则书上的文字等等，这些构成了一个系统，**整个系统是懂汉语的**。按照这个思路，塞尔犯了“**以偏概全**”的问题，不能因为整个系统中的一个成员不懂汉语就推出整个系统不懂汉语。

上述两种思路都首先认可了塞尔所说的汉字屋系统的有效性，及汉字屋系统和计算机系统之间的同构关系，整个论证才得以进行，然后加以辩驳。但有的人认为，塞尔在很**根本的问题**上就开始错了。

### 3.自我矛盾

塞尔原始设想中有三个预设：

1. 汉字屋系统与计算机系统之间是同构的。
2. 即使整个汉字屋系统能够通过汉语测试，汉字屋中的人也不懂汉语。
3. 我们不能从系统的外部行为特征中判断其内部是否具有智能。

实际上，这三点之间**存在矛盾**，我们可以使用**反证法**来论证：

1. 汉字屋系统和计算机系统之间存在着实质性的可类比关系。
2. 汉字屋论证的有效性，必须以 1 为必要前提。
3. 汉字屋论证的一个核心目标是，一个系统在外部行为上具有语言智能，并不能代表其真的具有智能（即我们不能从系统的外部行为特征中判断其内部是否具有智能）。
4. 由于1，汉字屋中规则书对应于计算机系统中的程序。
5. 假设系统硬件条件不变的情况下，AI 系统智能程度的高下关键在于如何编写程序，不执行任何程序的纯硬件没有任何智能。
6. 由于 4 和 5 ，整个汉字屋系统通过汉语测试的能力的高下取决于规则书的编制水平，而屋中的人本身是谈不上智能的，他必须要执行某种程序才能体现出这种程序的智能。
7. 即使整个汉字屋系统能够通过汉语测试，汉字屋中的人也不懂汉语。

那么为何认为 7 是正确的呢？逻辑上只有两种可能性（关键的一步）：

8. A ：屋内的人具有某种**内部思考能力**，以确定自己不懂汉语。这是塞尔会认为 7 的第一个道理。

 B：我们可以从屋内人的外部行为中确定他不懂汉语。

8A 和 8B 分别是从**内外两个视角**分析，因此含盖了所有可能性。

9. 若 8A 是真的，那和 6 矛盾，因为屋内人的内部思考能力的存在就等于说他可以执行一个独立于规则书的程序。
10. 若 8B 是真的，则和 3 矛盾。
11. 因此塞尔没有理由说明 7 是正确的，这导致了整个汉字屋论证的崩溃。
12. 总之，为了维护“屋中人也不懂汉语”这个步骤的有效性，我们要么否定汉字屋系统和计算机系统之间的类比的有效性，要么就要放弃整个论证的反行为主义目标。无论如何，这都会**导致整个汉字屋论证的崩溃**。

因此，塞尔的汉字屋类比是不太成功的，他过多地把自己的**直觉**牵扯到了这个类比里面，没有看清楚这种类比是有**缺陷性**的。

那么，塞尔的汉字屋实验到底有没有驳倒了图灵测试呢？这个问题和其他许多哲学问题一样，仁者见仁，智者见智。总之，汉字屋实验吸引了世界上最优秀的哲学家们的讨论和思考，对推动哲学和人工智能科学的发展有着不可磨灭的贡献。

那么你的观点呢？

## Reference

[复旦大学公开课：人工智能哲学](http://open.163.com/special/cuvocw/rengongzhinengzhexue.html)
