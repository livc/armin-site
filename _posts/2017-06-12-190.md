---
title: Image Caption 评价标准——BLEU
layout: post
permalink: /190
categories:
  - DeepLearning
tags:
  - ImageCaption
---

在 Image Caption 任务中，几种评价算法被用来度量预测结果（candidate caption）与 label （reference captions）的差异，这个系列主要介绍这几种评价标准。

## 符号定义

- $$ I_{i} $$ 为图像 $$i$$
- candidate caption $$c_{i}$$ 为模型预测结果句子
- reference captions $$ S_{i} = \{s_{i1}…s_{im}\} \in S$$  为训练图片的 label，也就是需要学习的句子（一幅图片被标注了多个句子）
- 图像语句使用 $$n$$-gram 来表示，一个 $$n$$-gram $$w_{k} \in \Omega$$是一个或多个（其实就是 n 个）有序单词的集合，我们只谈论 $$n$$-gram 从 1 个单词到 4 个单词的情况。
- $$h_{k}(s_{ij})$$ 为一个 $$n$$-gram $$w_{k}$$ 在 reference caption $$s_{ij}$$ 中出现的次数
- $$h_{k}(c_{i})$$ 为一个 $$n$$-gram $$w_{k}$$ 在 candidate caption $$c_{i}$$ 中出现的次数

## BLEU

[BLEU](https://en.wikipedia.org/wiki/BLEU) 是一种在机器翻译中度量 candidate 句子和 reference 句子间 $$n$$-gram 的相关性的方法。我们先给出数学定义，然后根据一个例子来看看 BLEU 具体是如何工作的。

它计算整个语料库中 $$n$$-gram 精度：
$$
CP_{n}(C,S)=\dfrac{\sum_{i}\sum_{k}\min(h_{k}(c_{i}),\max\limits_{j \in m}h_{k}(s_{ij}))}{\sum_{i}\sum_{k}h_{k}(c_{i})}
$$
其中，$$k$$ 为这组 $$n$$-gram 的索引，

引入**惩罚值（brevity penalty）**为：
$$
b(C,S)=\{^{1\qquad\qquad\mathrm{if}\;l_{C}>l_{S}}_{e^{1-l_{S}/l_{C}} \qquad \mathrm{if}\; l_{C}\leq l_{S} }
$$
其中，$$l_{C}$$ 为候选句子 $$c_{i}$$ 的总长度，$$l_{S}$$ 为参考句子长度（**当有多个参考句子时选择长度最接近候选句子长度的那个**）。

最终计算 BLUE 分数，它实际上是 $$n$$-gram 精度的加权几何平均：
$$
BLEU_{N}(C,S)=b(C,S)\exp \left( \sum^{N}_{n=1}w_{n}\log CP_{n}(C,S)\right)
$$
其中，$$ N=1,2,3,4$$ 并且对于所有的 $$n$$， $$w_{n}$$ 是常量。

随着 $$n$$ 的增加，BLEU 在语料库层级上的匹配效果较好，在句子层级上的匹配效果越来越差。因此 BLEU 在评估独立句子时表现糟糕。

接下来我们根据[维基百科](https://en.wikipedia.org/wiki/BLEU)上的例子看一下 BLEU 是如何工作的，这个例子展示了糟糕的预测结果却得到了很高的一元组（unigram）精度分数。

**<img src="https://ws1.sinaimg.cn/large/9cd77f2ely1fgigq2qpb5j20ry0biq3z.jpg" width="70%" />**

表中第一行为预测结果，下面两行为训练集中的图片描述。候选句子的七个单词都出现在参考句子中，所以候选句子的一元组精度为
$$
P = \dfrac{m}{w_{t}}=\dfrac{7}{7}=1
$$
其中，$$m$$ 为候选句子中的单词出现在参考句子中的个数，$$w_{t}$$ 是候选句子的单词总数。所以可以看到，这是一个很完美的得分，但是实际的效果非常差。

BLEU 的修改非常直接，对于候选句子中的每个单词，算法计算它出现在每个参考句子中的最大次数， $$\max\limits_{j \in m}h_{k}(s_{ij}))$$。比如说，在上面的例子中，the 在参考句子 1 中出现了 2 次，在参考句子2 中出现了 1 次，所以 $$\max\limits_{j \in m}h_{k}(s_{ij}))=2$$。

对于候选句子，记录每个单词的出现次数 $$h_{k}(c_{i}) $$ ，比如对于 the，值为 7，那么 $$ \min(h_{k}(c_{i}),\max\limits_{j \in m}h_{k}(s_{ij}))$$ 的值为 $$\min{(7,2)}=2$$ ，因此 $$CP_{n}(C,S)=\dfrac{2}{7}$$。

实际上，使用单个单词（unigram）来比较并不理想，所以 BLEU 使用  $$n$$-gram 来计算。

**BLEU 在短句子上表现的精度非常高**，假如上例中的候选句子为

> the cat

而参考句子不变，那么$$CP_{n}(C,S)=\dfrac{1+1}{1+1}=1$$。如果是二元组（bigram）结果同样为 1。

为了解决**很短的句子产生很高的分数**这个问题，BLEU 引入**惩罚值（brevity penalty）**，即 $$b(C,S)$$。当 $$l_{C}\leq l_{S}$$ 时，惩罚生效，具体计算如前面的的式子。

## References

- <https://arxiv.org/abs/1504.00325>
- <https://en.wikipedia.org/wiki/BLEU>