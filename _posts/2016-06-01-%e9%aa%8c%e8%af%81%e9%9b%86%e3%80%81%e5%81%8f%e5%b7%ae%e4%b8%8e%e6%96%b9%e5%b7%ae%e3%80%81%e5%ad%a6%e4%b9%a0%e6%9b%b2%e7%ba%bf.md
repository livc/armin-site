---
title: 验证集、偏差与方差、学习曲线
layout: post
permalink: /blog/151
categories:
  - 机器学习
tags:
  - 交叉验证
  - 偏差
  - 方差
---
<div id="wmd-preview-section-2835" class="wmd-preview-section preview-content">
  <h2 id="验证集">
    验证集
  </h2>
  
  <p>
    机器学习的数据分为三类：训练集、验证集和测试集，刚开始看tensorflow时一直没搞懂验证集是做什么的。
  </p>
  
  <p>
    <img title="" src="https://i0.wp.com/ww2.sinaimg.cn/mw690/9cd77f2ejw1f4g0ckmgt1j20ef0613yj.jpg" alt="图1" data-recalc-dims="1" />
  </p>
  
  <p>
    假如要在10个不同次数的多项式间选择，那么训练集就是训练参数每个式子的参数θ，验证集就是用来选择这十个式子哪个误差最小的，因为参数是用训练集训练出的，所以如果再用训练集数据去比较哪个式子误差小会不准确。
  </p>
  
  <p>
    一般训练集数据占60%，验证集和测试集各20%。
  </p>
</div>

<div id="wmd-preview-section-2848" class="wmd-preview-section preview-content">
  <h2 id="误差与多项式次数">
    误差与多项式次数
  </h2>
  
  <p>
    <img title="" src="https://i1.wp.com/ww3.sinaimg.cn/mw690/9cd77f2ejw1f4g0cl9nxtj20ta0gggn1.jpg" alt="图2" data-recalc-dims="1" />
  </p>
  
  <p>
    如图是训练集代价误差和验证集代价误差与多项式次数的关系。
  </p>
  
  <p>
    对于训练集来说，d较小时，模型拟合程度低，误差大，随着d的增长误差越来越小，拟合程度越来越高。（最后会<strong>过拟合</strong>，但是对于训练集的代价函数误差一直是变小）。
  </p>
  
  <p>
    对于交叉验证集来说，d较小时，拟合程度低，误差大，随着d的增大，误差变小，之后由于过拟合，误差又会变大。
  </p>
  
  <p>
    <img title="" src="https://i2.wp.com/ww3.sinaimg.cn/mw690/9cd77f2ejw1f4g0ckywpgj20h00bnt8v.jpg" alt="图3" data-recalc-dims="1" />
  </p>
  
  <p>
    训练集误差和验证集误差近似时：偏差（欠拟合）<br /> 验证集误差远大于训练集误差时：方差（过拟合）
  </p>
</div>

<div id="wmd-preview-section-2855" class="wmd-preview-section preview-content">
  <h2 id="正则化与偏差方差">
    正则化与偏差/方差
  </h2>
  
  <p>
    常用正则化方法来防止过拟合，因此参数的选择也要思考类似的问题。
  </p>
  
  <p>
    λ越大，就会越减少过拟合现象的出现。
  </p>
  
  <p>
    λ的选择通常是 0-10 之间的呈现 2 倍关系的值（如：0,0.01,0.02,0.04,0.08,0.15,0.32,0.64,1.28,2.56,5.12,10 共 12 个）
  </p>
  
  <p>
    <img title="" src="https://i1.wp.com/ww4.sinaimg.cn/mw690/9cd77f2ejw1f4g0clnqj5j20w00gi0ts.jpg" alt="图4" data-recalc-dims="1" />
  </p>
  
  <ul>
    <li>
      λ 较小时，训练集误差较小（过拟合）而交叉验证集误差较大
    </li>
    <li>
      随着 λ 的增加，训练集误差不断增加（欠拟合），而交叉验证集误差则是先减小后增加
    </li>
  </ul>
</div>

<div id="wmd-preview-section-2868" class="wmd-preview-section preview-content">
  <h2 id="学习曲线">
    学习曲线
  </h2>
  
  <p>
    学习曲线就是一种很好的工具，我们经常使用学习曲线来判断某一个学习算法是否处于偏差、方差问题。学习曲线是学习算法的一个很好的 合理检验（sanity check）。
  </p>
  
  <p>
    学习曲线是将训练集误差和交叉验证集误差作为训练集实例数量（m）的函数绘制的图表。
  </p>
  
  <p>
    如何利用学习曲线识别高偏差（欠拟合）、高方差（过拟合）？
  </p>
  
  <p>
    作为例子，我们尝试用一条直线来适应下面的数据，可以看出，无论训练集有多么大误差都不会有太大改观。
  </p>
  
  <p>
    <img title="" src="https://i2.wp.com/ww4.sinaimg.cn/mw690/9cd77f2ejw1f4g0cm536vj20sb0h874u.jpg" alt="图5" data-recalc-dims="1" />
  </p>
  
  <p>
    如图所示，高偏差（欠拟合）的情况下，增加数据到训练集不一定能有帮助。
  </p>
  
  <p>
    <img title="" src="https://i1.wp.com/ww2.sinaimg.cn/mw690/9cd77f2ejw1f4g0cmkbp8j20uy0hnt99.jpg" alt="图6" data-recalc-dims="1" />
  </p>
  
  <p>
    假设我们使用一个非常高次的多项式模型，并且正则化非常小，可以看出，当交叉验证集误差远大于训练集误差时，往训练集增加更多数据可以提高模型的效果。
  </p>
  
  <p>
    也就是说在高方差（过拟合）的情况下，增加更多数据到训练集可能可以提高算法效果。
  </p>
</div>

<div id="wmd-preview-section-2809" class="wmd-preview-section preview-content">
  <h2 id="例子">
    例子
  </h2>
  
  <p>
    让我们来看一看我们在什么情况下应该怎样选择：
  </p>
  
  <ul>
    <li>
      获得更多的训练实例——解决高方差
    </li>
    <li>
      尝试减少特征的数量——解决高方差
    </li>
    <li>
      尝试获得更多的特征——解决高偏差
    </li>
    <li>
      尝试增加多项式特征——解决高偏差
    </li>
    <li>
      尝试减少正则化程度 λ——解决高偏差
    </li>
    <li>
      尝试增加正则化程度 λ——解决高方差
    </li>
  </ul>
</div>